% vim:syntax=tex

Our study has limitations that impact the validity of our findings,
as well as our ability to generalize them.
We describe some of these limitations and their impacts.

Threats to construct validity concern the adequacy of the study procedure with regard to
measurement of the concepts of interest and can arise due to poor measurement design.
Threats to construct validity include the use of cosine similarity as our measure of similarity for corpora
and the use of topic distinctness to evaluate the topic models.

Threats to internal validity include possible defects in our tool chain and possible errors
in our execution of the study procedure,
the presence of which might affect the accuracy of our results and the conclusions we draw from them.
We controlled for these threats by testing our tool chain and by assessing the quality of our data.
Because we applied the same tool chain to all subject systems, any errors are systematic and are unlikely
to affect our results substantially.


\begin{figure}[t]
\footnotesize

{\bf bookkeeper-server.src.main.java.}org.apache.bookkeeper.bookie.Bookie

{\bf bookkeeper-server.src.main.java.}org.apache.bookkeeper.bookie.EntryLogger

{\bf bookkeeper-server.src.test.java.}org.apache.bookkeeper.bookie.LedgerCacheTest

\caption{Corrected BookKeeper goldset for issue \#10. Bold text denotes the portion removed.}
\label{fig:goldsetfix}
\vspace{-10pt}
\end{figure}


Additionaly, we found errors within the datasets themselves that would be a threat to internal validity.
In particular, the Moreno et al. dataset included classes that had package names that were not valid.
Figure~\ref{fig:goldsetfix} describes the classes reported in the dataset
and the corrected classes.
We make the assumption that the authors of this dataset used the directory structure of the project to build the package names.
Manual correction was required as our tool parses the files and uses the package name given in the source file, not the directory structure.

Another threat to internal validity pertains to the value of parameters such as $K$ that we selected for all models trained.
We decided that the changeset and snapshot models should have the same parameters to help facilitate evaluation and comparison.
We argue that our study is not about selecting the best parameters,
but to show that our changeset topic-model-based FLT approach is reasonable.

Threats to external validity concern the extent to which we can generalize our results.
The subjects of our study comprise fourteen open source projects in Java,
so we cannot generalize our results to systems implemented in other languages.
However, the systems are of different sizes, are from different domains, and
have characteristics in common with those of systems developed in industry.

